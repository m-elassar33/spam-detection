{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "\n",
      "precision:  0.997885835095\n",
      "recall:  0.995780590717\n",
      "f-score:  0.996832101373 \n",
      "\n",
      "K Neighbors Classifier\n",
      "\n",
      "precision:  0.969325153374\n",
      "recall:  1.0\n",
      "f-score:  0.984423676012 \n",
      "\n",
      "Random Forest Classifier\n",
      "\n",
      "precision:  0.977272727273\n",
      "recall:  0.997890295359\n",
      "f-score:  0.987473903967 \n",
      "\n",
      "Classifying using Readability Features\n",
      "\n",
      "precision:  0.826315789474\n",
      "recall:  0.993670886076\n",
      "f-score:  0.902298850575 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import pyphen\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "# Reading and Preprocessing Data\n",
    "\n",
    "emails = []\n",
    "labels = []\n",
    "\n",
    "#Read all the emails in the ten folders\n",
    "for root, dirs, files in os.walk('lingspam_public/bare'):\n",
    "    for file in files:\n",
    "        if file != '.DS_Store':\n",
    "            with open(os.path.join(root,file), 'r') as f:\n",
    "                emails.append(f.read())\n",
    "                #Save the labels (spam/not spam, or 0/1) of each email to a list\n",
    "                if 'spm' in file:\n",
    "                    labels.append(0)\n",
    "                else:\n",
    "                    labels.append(1)\n",
    "                    \n",
    "#Split the emails and labels into 80% training and 20% testing\n",
    "emails_train, emails_test, labels_train, labels_test = train_test_split(emails, labels, test_size = 0.2, random_state = 0)\n",
    "\n",
    "#Fit and transform the training emails and transform the testing emails using a CountVectorizer\n",
    "v = CountVectorizer()\n",
    "transformed_emails_train = v.fit_transform(emails_train)\n",
    "transformed_emails_test = v.transform(emails_test)\n",
    "\n",
    "# Scikit-Learn Classifiers\n",
    "\n",
    "#Multinomial Naive Bayes\n",
    "print('Multinomial Naive Bayes\\n')\n",
    "\n",
    "mnb_clf = MultinomialNB(alpha=1)\n",
    "mnb_clf.fit(transformed_emails_train, labels_train)\n",
    "mnb_predictions = mnb_clf.predict(transformed_emails_test)\n",
    "\n",
    "print('precision: ', metrics.precision_score(labels_test, mnb_predictions))\n",
    "print('recall: ', metrics.recall_score(labels_test, mnb_predictions))\n",
    "print('f-score: ', metrics.f1_score(labels_test, mnb_predictions),'\\n')\n",
    "\n",
    "#K Neighbors Classifier\n",
    "print('K Neighbors Classifier\\n')\n",
    "\n",
    "kn_clf = KNeighborsClassifier()\n",
    "kn_clf.fit(transformed_emails_train, labels_train)\n",
    "kn_predictions = kn_clf.predict(transformed_emails_test)\n",
    "\n",
    "print('precision: ', metrics.precision_score(labels_test, kn_predictions))\n",
    "print('recall: ', metrics.recall_score(labels_test, kn_predictions))\n",
    "print('f-score: ', metrics.f1_score(labels_test, kn_predictions),'\\n')\n",
    "\n",
    "#Random Forest Classifier\n",
    "print('Random Forest Classifier\\n')\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(transformed_emails_train, labels_train)\n",
    "rf_predictions = rf_clf.predict(transformed_emails_test)\n",
    "\n",
    "print('precision: ', metrics.precision_score(labels_test, rf_predictions))\n",
    "print('recall: ', metrics.recall_score(labels_test, rf_predictions))\n",
    "print('f-score: ', metrics.f1_score(labels_test, rf_predictions),'\\n')\n",
    "\n",
    "# Classifying using Readability Features\n",
    "\n",
    "#A list for every feature, where every element is the feature value of a given email\n",
    "\n",
    "#The number of sentences in an email\n",
    "\n",
    "f1 = [len(email.split('.')) for email in emails]\n",
    "\n",
    "#The number of verbs in an email\n",
    "\n",
    "f2 = []\n",
    "\n",
    "for email in emails:\n",
    "    tagged_email = pos_tag(word_tokenize(email))\n",
    "    count_verb = 0\n",
    "    for word_tag_tuple in tagged_email:\n",
    "        if word_tag_tuple[1] == 'VB':\n",
    "            count_verb+=1\n",
    "    f2.append(count_verb)\n",
    "\n",
    "#The number of words containing both numeric and alphabetical characters\n",
    "\n",
    "def contains_num_alpha(word):\n",
    "    return any(char.isdigit() for char in word) and any(char.isalpha() for char in word)\n",
    "\n",
    "f3 = []\n",
    "\n",
    "for email in emails:\n",
    "    count_contains_num_alpha = 0\n",
    "    for word in word_tokenize(email):\n",
    "        if contains_num_alpha(word):\n",
    "            count_contains_num_alpha+=1\n",
    "    f3.append(count_contains_num_alpha)\n",
    "\n",
    "#The number of words in an email that are found in the spam list\n",
    "\n",
    "with open('spam-term-list', 'r') as f:\n",
    "    spam_term_list = f.read().split('\\n')\n",
    "\n",
    "f4 = []\n",
    "\n",
    "for email in emails:\n",
    "    count_spam = 0\n",
    "    for word in word_tokenize(email):\n",
    "        if word in spam_term_list:\n",
    "            count_spam+=1\n",
    "    f4.append(count_spam)\n",
    "\n",
    "#init pyphen dic\n",
    "    \n",
    "dic = pyphen.Pyphen(lang='en_GB')\n",
    "\n",
    "#The number of words in an email that have more than 3 syllables\n",
    "\n",
    "f5 = []\n",
    "\n",
    "for email in emails:\n",
    "    more_than_three_sylls_count = 0\n",
    "    for word in word_tokenize(email):\n",
    "        if len(dic.inserted(word).split('-')) > 3:\n",
    "            more_than_three_sylls_count+=1\n",
    "    f5.append(more_than_three_sylls_count)\n",
    "    \n",
    "#The average number of syllables of words in an email\n",
    "\n",
    "f6 = []\n",
    "\n",
    "for email in emails:\n",
    "    all_sylls = 0\n",
    "    for word in word_tokenize(email):\n",
    "        all_sylls+=len(dic.inserted(word).split('-'))\n",
    "    f6.append(all_sylls/len(word_tokenize(email)))\n",
    "    \n",
    "#A feature matrix (list of lists), where every row corresponds to an email,\n",
    "# and every column corresponds to a feature value of this email\n",
    "    \n",
    "feat_matrix = [[f1[i], f2[i], f3[i], f4[i], f5[i], f6[i]] for i in range(len(emails))]\n",
    "\n",
    "#Feeding the feature matrix and the labels to the classifier\n",
    "\n",
    "new_labels = []\n",
    "for label in labels:\n",
    "    new_labels.append(label)\n",
    "\n",
    "emails_train_new, emails_test_new, labels_train_new, labels_test_new = train_test_split(feat_matrix, new_labels, test_size = 0.2, random_state = 0)\n",
    "\n",
    "clf = SVC()\n",
    "\n",
    "clf.fit(emails_train_new, labels_train_new)\n",
    "\n",
    "new_predictions = clf.predict(emails_test_new)\n",
    "\n",
    "print('Classifying using Readability Features\\n')\n",
    "\n",
    "print('precision: ', metrics.precision_score(labels_test_new, new_predictions))\n",
    "print('recall: ', metrics.recall_score(labels_test_new, new_predictions))\n",
    "print('f-score: ', metrics.f1_score(labels_test_new, new_predictions),'\\n')\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
